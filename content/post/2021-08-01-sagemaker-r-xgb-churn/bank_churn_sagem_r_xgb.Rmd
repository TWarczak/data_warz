---
title: "Predicting Bank Customer Churn using AWS SageMaker and XGBoost in Local RStudio"
output: md_document
author: Todd Warczak
date: '2021-08-03'
slug: modeltime
categories:
   - rstats
   - AWS
   - SageMaker
   - XGBoost
   - R
tags:
   - rstats
   - AWS
   - reticulate
   - XGBoost
   - R
summary: "For this post, I experimented using AWS SageMaker with the AWS built-in XGBoost algorithm from within my local RStudio to predict whether a bank customer has churned. The data comes from the SLICED season 1 episode 7 Kaggle competition. SLICED is a data science competition where contestants are given a never-before-seen dataset and two-hours to code a solution to a prection challenge."
featured: "featured-hex-modeltime.jpeg"
image:
   caption: ''
   focal_point: ''
   preview_only: true
output: md_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r library, echo=TRUE}
library(tidymodels)
library(tidyverse)
#library(scales)
#library(stacks)        # 
library(corrmorant)    # correlation matrix
library(patchwork)     # multiple plots to 1 plot
library(reticulate)    # calling the SageMaker Python SDK from R
library(pROC)          # ROC curves
library(viridis)       # color palletes
library(caret)         # 
```

-   [ü•Ö Project Goal](#goal)
-   [üóÇ Obtain Data](#data)
-   [üõÅ Clean Data](#clean)
-   [üî≠ Explore Data](#explore)
-   [üßÆ AWS Setup](#aws)
-   [üèó Train XGBoost](#build)
-   [üîß Tune XGBoost](#tune)
-   [üèÜ Select Best Model](#best)
-   [üéØ Predict Holdout](#holdout)
-   [üì¨ Submission](#submit)

## ü•Ö Goal of this Project {#goal}

Predict whether a bank customer will churn using AWS SageMaker and RStudio

## üóÇ Obtain Data {#data}

The data comes from the Kaggle competition
[SLICED](https://www.kaggle.com/c/sliced-s01e07-HmPsw2/overview).

```{r chunk3, message=FALSE, warning=FALSE}
churn_data <- read_csv("~/Documents/R/data_warz/content/post/2021-08-01-sagemaker-r-xgb-churn/train.csv")

holdout <- read_csv("~/Documents/R/data_warz/content/post/2021-08-01-sagemaker-r-xgb-churn/test.csv")
# holdout does not contain 'attrition_flag'. Use to run inference and produce a .csv file 
# that contains only 2 columns: "id" (those found in holdout) and inferred "attrition_flag".  
```

## üõÅ Clean Data {#clean}

```{r chunk4}
glimpse(churn_data)
```

### [Data Dictionary]

#### Outcome Variable

-   attrition_flag: whether the customer is churned (0 = no; 1 = yes)

#### ID

-   id: unique identifier for the customer

#### Categorical Features

-   gender
-   education_level
-   income_category: income range of the customer

#### Numeric Features

-   customer_age

-   total_relationship_count: number of relationships

-   months_inactive_12_mon: number of months the customer is inactive in past 12
    months

-   credit_limit

-   total_revolving_bal: customer's total revolving balance

-   total_amt_chng_q4_q1: amount the balance changed from Q4 to Q1

-   total_trans_amt: value of all the customer's transactions in the period

-   total_trans_ct: count of all the customer's transactions

-   total_ct_chng_q4_q1: difference in number of the customer's transactions from Q4
    to Q1

-   avg_utilization_ratio: customer's average utilization ratio during the period


```{r chunk5}
skimr::skim_without_charts(churn_data)
```

Not much cleaning to do. For EDA I want the `attrition_flag` variable to be obvious whether the customer has churned or not. I'll factor the categorical variables and experiment with log transforming some numeric variables. 

##  üî≠ Explore Data {#explore}

```{r chunk6, message=FALSE, warning=FALSE}
churn_data2 <- churn_data %>% 
  mutate(churned = factor(ifelse(attrition_flag == 1, "yes", "no"),
                          levels = c("no", "yes"))) %>%
  mutate(education_level = fct_relevel(education_level, c("Unknown", 
                                                          "Uneducated", 
                                                          "High School", 
                                                          "College", 
                                                          "Graduate", 
                                                          "Doctorate", 
                                                          "Post-Graduate"))) %>%
  mutate(income_category = fct_relevel(income_category, c("Unknown",
                                                          "Less than $40K",
                                                          "$40K - $60K",
                                                          "$60K - $80K",
                                                          "$80K - $120K",
                                                          "$120K +")))

churn_data3 <- churn_data2 %>% 
               mutate(across(.cols = c(credit_limit, total_trans_amt),
                             .fns  = log1p)) %>%
               mutate(across(.cols = c(credit_limit, total_trans_amt), 
                             .fns = timetk::standardize_vec)) %>% 
               select(-c(id, attrition_flag))
```

Let's look at a correlation matrix of all the numeric variables. We can group by our new `churned` variable to see features that correlate differently based on the churn outcome.  

```{r chunk7, message=FALSE, warning=FALSE}

corfun <- function(x, y)  {
  round(cor(x, y, method = "pearson", use = "pairwise.complete.obs"), 2)
}

ggcorrm(churn_data3, aes(col = churned, fill = churned), bg_dia  = "grey30") +
    lotri(geom_point(alpha = 0.1)) +
    lotri(geom_smooth(se=F, method = "loess")) +
    utri_funtext(fun = corfun, size = 6) +
    dia_names(y_pos = 0.15, size = 3) +
    dia_density(lower = 0.3, fill = "grey60", color = 1) +
    theme_dark() +
    scale_color_viridis_d() +
    scale_fill_viridis_d() +
    labs(title = "Correlation Plot")
```




```{r chunk8}
dense <- churn_data3 %>%
         select(-c(gender, education_level, income_category)) %>%
         pivot_longer(cols = c(customer_age:avg_utilization_ratio), 
                      names_to = "feature", 
                      values_to = "value")

ggplot(dense, aes(value, fill = churned)) +
  geom_density(alpha = .5) +
  facet_wrap(~ feature, scales = "free") +
  labs(title = "Numeric features impacting churn?")
```




```{r chunk9}
churn_data %>% 
  ggplot(aes(total_trans_amt, total_trans_ct, z = attrition_flag)) +
  stat_summary_hex(alpha = 0.8, bins = 50) +
  scale_fill_viridis_c() +
  labs(fill = "% Churned") +
  theme_dark()

churn_data %>% 
  ggplot(aes(total_ct_chng_q4_q1, total_trans_ct, z = attrition_flag)) +
  stat_summary_hex(alpha = 0.8, bins = 50) +
  scale_fill_viridis_c() +
  labs(fill = "% Churned") +
  theme_dark()

churn_data %>% 
  ggplot(aes(credit_limit, avg_utilization_ratio, z = attrition_flag)) +
  stat_summary_hex(alpha = 0.8, bins = 50) +
  scale_fill_viridis_c() +
  labs(fill = "% Churned") +
  theme_dark()

churn_data %>% 
  ggplot(aes(total_trans_amt, total_amt_chng_q4_q1, z = attrition_flag)) +
  stat_summary_hex(alpha = 0.8, bins = 60) +
  scale_fill_viridis_c() +
  labs(fill = "% Churned") +
  theme_dark()
```

```{r chunk10, echo=FALSE}
cat_feat <- churn_data2 %>% 
  select(c(gender, education_level, income_category, churned))

n_gen <- cat_feat %>% 
  group_by(gender) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(gender, count)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = count),
            color    = "white",
            size     = 3,
            fontface = 'bold',
            hjust    = 1.2,
            vjust    = 0.4) +
        theme_minimal() +
        theme(legend.position = 'none',
              axis.title.x = element_blank())

n_edu <- cat_feat %>% 
  group_by(education_level) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(education_level, count)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = count),
            color    = "white",
            size     = 3,
            fontface = 'bold',
            hjust    = 1.2,
            vjust    = 0.4) +
        theme_minimal() +
        theme(legend.position = 'none')

n_inc <- cat_feat %>% 
  group_by(income_category) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(income_category, count)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = count),
            color    = "white",
            size     = 3,
            fontface = 'bold',
            hjust    = 1.2,
            vjust    = 0.4) +
        theme_minimal() +
        theme(legend.position = 'none')

n_chrn <- cat_feat %>% 
  group_by(churned) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(churned, count)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = count),
            color    = "white",
            size     = 3,
            fontface = 'bold',
            hjust    = 1.2,
            vjust    = 0.4) +
        theme_minimal() +
        theme(legend.position = 'none',
              axis.title.x = element_blank())

n_chrn + n_gen + n_edu + n_inc +
plot_layout(ncol = 2, heights = c(0.7,2)) +
plot_annotation(title = "Counts of Each Categorical Variable in Training Data")
```

```{r chunk11, echo=FALSE}
gen <- ggplot(cat_feat %>% 
                group_by(gender, churned) %>% 
                summarise(n = n()) %>% 
                mutate(percent_churned = prop.table(n)*100) %>% 
                filter(churned == 'yes'),
               aes(gender, percent_churned)) +
        geom_col() +
        coord_flip() +
        geom_text(aes(label = round(percent_churned, digits = 1)),
                  color    = "white",
                  size     = 4,
                  fontface = 'bold',
                  hjust    = 1.3,
                  vjust    = 0.4) +
        theme_minimal() +
        theme(legend.position = 'none')

ed <- ggplot(cat_feat %>% 
                group_by(education_level, churned) %>% 
                summarise(n = n()) %>% 
                mutate(percent_churned = prop.table(n)*100) %>% 
                filter(churned == 'yes'),
             aes(education_level, percent_churned)) +
        geom_col() +
        coord_flip() +
        geom_text(aes(label = round(percent_churned, digits = 1)),
                    color    = "white",
                    size     = 4,
                    fontface = 'bold',
                    hjust    = 1.3,
                    vjust    = 0.4) +
        theme_minimal() +
        theme(axis.title.x = element_blank(),
              legend.position = 'none')

inc <- ggplot(cat_feat %>% 
                group_by(income_category, churned) %>% 
                summarise(n = n()) %>% 
                mutate(percent_churned = prop.table(n)*100) %>% 
                filter(churned == 'yes'),
              aes(income_category, percent_churned)) +
        geom_col() +
        coord_flip() +
        geom_text(aes(label = round(percent_churned, digits = 1)),
                    color    = "white",
                    size     = 4,
                    fontface = 'bold',
                    hjust    = 1.3,
                    vjust    = 0.4) +
        theme_minimal() +
        theme(axis.title.x = element_blank(),
              legend.position = 'none')

ed + inc + gen +
    plot_layout(ncol = 2, heights = c(2,0.7)) +
    plot_annotation(title = "Percentage of Each Categorical Variable that Churned")

```

```{r chunk12, echo=FALSE}
cat_feat %>%
  pivot_longer(gender:income_category) %>%
  ggplot(aes(y = value, fill = churned)) +
  geom_bar(position = "fill") +
  facet_wrap(vars(name), scales = "free", ncol = 1) +
  theme_minimal() +
  labs(x = NULL, y = NULL)
```

```{r chunk13}
use_condaenv("sagemaker-r", required = TRUE)
sagemaker <- import("sagemaker")
session <- sagemaker$Session()
```

```{r chunk14}
# bucket <- session$default_bucket()
bucket <- "twarczak-sagemaker3"
project <- "churn"
data_path <- paste0("s3://", bucket, "/", project, "/", "data")
models_path <- paste0("s3://", bucket, "/", project, "/", "models")
```

We will be using Bayesian Optimation for hyperparameter tuning without cross-validation. 

```{r chunk15}
# Make 70/15/15 Train/Validate/Test split

set.seed(333)
splits  <- initial_split(churn_data, prop = 0.70, strata = attrition_flag)

train <- training(splits)
other  <- testing(splits)

splits2 <- initial_split(other, prop = 0.50, strata = attrition_flag)
validation <- training(splits2)
test <- testing(splits2)

id_holdout    <- holdout    %>% select(id)

print(splits)
print(splits2)
```

```{r chunk16}
churn_rec <- recipe(attrition_flag ~ ., data = train) %>% 
             step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
             step_rm(id) %>% 
             prep()

churn_training <- churn_rec %>% 
                  juice() %>% 
                  select(attrition_flag, everything()) # just to put attrition_flag as 1st column

churn_validation <- bake(churn_rec, new_data = validation) %>% 
                    select(attrition_flag, everything()) # just to put attrition_flag as 1st column

churn_test <- bake(churn_rec, new_data = test) %>% 
              select(attrition_flag, everything()) # just to put attrition_flag as 1st column

churn_holdout <- bake(churn_rec, new_data = holdout)
```
```{r chunk17}
bst <- xgboost::xgboost(data = data.matrix(subset(churn_training, select = -attrition_flag)), 
               label = churn_training$attrition_flag, max_depth = 2, eta = 0.5, nthread = 2, nrounds = 100, 
               objective = "binary:logistic")

imp_bst <- xgb.importance(colnames(churn_training), model = bst)
xgb.ggplot.importance(imp_bst)

vip::vip(bst, geom = 'point', num_features = 15)
```




```{r chunk18, message=FALSE}

dir.create("../2021-08-01-sagemaker-r-xgb-churn/data")

write_csv(churn_training, 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_training.csv", 
          col_names = FALSE)
write_csv(churn_validation, 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_validation.csv", 
          col_names = FALSE)
write_csv(churn_test %>% select(-attrition_flag), 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_test.csv", 
          col_names = FALSE)
write_csv(churn_test, 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_test_2.csv", 
          col_names = TRUE) # Need this later to use with results


write_csv(churn_holdout, 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_holdout.csv", 
          col_names = FALSE) 
write_csv(id_holdout, 
          "../2021-08-01-sagemaker-r-xgb-churn/data/churn_holdout_id.csv",
          col_names = FALSE) # Need this later to use with holdout results
```


```{r chunk19}
s3_uploader <- sagemaker$s3$S3Uploader()

s3_train <- s3_uploader$upload(local_path = "../2021-08-01-sagemaker-r-xgb-churn/data/churn_training.csv", 
                               desired_s3_uri = data_path)

s3_validation <- s3_uploader$upload(local_path = "../2021-08-01-sagemaker-r-xgb-churn/data/churn_validation.csv",
                                    desired_s3_uri = data_path)

s3_test <- s3_uploader$upload(local_path = "../2021-08-01-sagemaker-r-xgb-churn/data/churn_test.csv", 
                              desired_s3_uri = data_path)


```

```{r chunk20}
region <- session$boto_region_name
# get container image location
container <- sagemaker$image_uris$retrieve(framework = "xgboost", 
                                           region    = region, 
                                           version   = "1.3-1" )
# get SageMaker execution role stored in .Renviron
role_arn <- Sys.getenv("SAGEMAKER_ROLE_ARN")
# Create an Estimator object
xgb_estimator <- sagemaker$estimator$Estimator(image_uri          = container,
                                               role               = role_arn,
                                               instance_count     = 1L,
                                               instance_type      = "ml.m5.4xlarge",
                                               volume_size        = 10L, #30L
                                               max_run            = 300L,
                                               output_path        = models_path,
                                               sagemaker_session  = session,
                                               use_spot_instances = TRUE,
                                               max_wait           = 300L )
```

```{r chunk21}
xgb_estimator$set_hyperparameters(objective        = "binary:logistic",
                                  eval_metric      = "auc",
                                  max_depth        = 5L, 
                                  eta              = 0.1,
                                  num_round        = 100L,
                                  colsample_bytree = 0.4,
                                  alpha            = 10L,
                                  min_child_weight = 1.1,
                                  subsample        = 0.7)
```

```{r chunk22}
# Create training job name based project organization principles
algo <- "xgb"
timestamp <- format(Sys.time(), "%Y-%m-%d-%H-%M-%S")
job_name <- paste(project, algo, timestamp, sep = "-")
s3_train_input <- sagemaker$inputs$TrainingInput(s3_data = s3_train,
                                                 content_type = 'csv')
s3_valid_input <- sagemaker$inputs$TrainingInput(s3_data = s3_validation,
                                                 content_type = 'csv')
input_data <- list('train'      = s3_train_input,
                   'validation' = s3_valid_input)
```

```{r chunk23}
xgb_estimator$fit(inputs = input_data,
                  job_name = job_name,
                  wait = FALSE)  # If set to TRUE, the call will wait until job completes
```

```{r chunk24}
session$describe_training_job(job_name)[["TrainingJobStatus"]]
```

```{r chunk25}
training_job_stats <- session$describe_training_job(job_name = job_name)
final_metrics <-  map_df(training_job_stats$FinalMetricDataList, 
                          ~tibble(metric_name = .x[["MetricName"]],
                                  value = .x[["Value"]]))
final_metrics
```

```{r chunk26}
predictions_path <- paste0(models_path, "/", job_name, "/predictions") 
xgb_batch_predictor <- xgb_estimator$transformer(instance_count = 1L, 
                                                 instance_type  = "ml.m5.xlarge", 
                                                 strategy       = "MultiRecord",
                                                 assemble_with  = "Line",
                                                 output_path    = predictions_path)
```

```{r chunk27}
xgb_batch_predictor$transform(data         = s3_test, 
                              content_type = 'text/csv',
                              split_type   = "Line",
                              job_name     = job_name,
                              wait         = FALSE) # If TRUE, call waits until job completes
```

```{r chunk28}
session$describe_transform_job(job_name)[["TransformJobStatus"]]
```

```{r chunk29}
s3_downloader <- sagemaker$s3$S3Downloader()
s3_test_predictions_path <- s3_downloader$list(predictions_path)
 
dir.create("./predictions")
s3_downloader$download( s3_test_predictions_path, "./predictions")
 
test_predictions <- read_csv("./predictions/churn_test.csv.out",
                              col_names = FALSE) %>% 
                    pull(X1)

test_results <- tibble(truth       = churn_test$attrition_flag,
                       predictions = test_predictions )

head(test_results)
```

```{r chunk30}
roc_obj <- roc(test_results$truth,
               test_results$predictions,
               plot        = TRUE,         
               grid        = TRUE,
               print.auc   = TRUE,
               legacy.axes = TRUE, 
               main        = "ROC curve for XGBoost classification",
               show.thres  = TRUE,
               col         = "red2" )
```

```{r chunk31}
conf_matrix <- caret::confusionMatrix(factor(ifelse(test_results$predictions >= 0.5, 1, 0),
                                             levels = c("0", "1"), 
                                             labels = c("retained", "churned")),
                                      factor(test_results$truth, 
                                             levels = c(0, 1), 
                                             labels = c("retained", "churned")),
                                      positive = "churned")

conf_matrix
```

```{r chunk32}
xgb_estimator$set_hyperparameters(objective        = "binary:logistic",
                                  min_child_weight = 1 )
```

```{r chunk33}
hyperp_ranges <- list(num_round = sagemaker$tuner$IntegerParameter(50L, 500L),
                      max_depth = sagemaker$tuner$IntegerParameter(2L, 15L),
                      eta =sagemaker$tuner$ContinuousParameter(0.01,0.4,"Logarithmic"),
                      colsample_bytree = sagemaker$tuner$ContinuousParameter(0.3,0.8),
                      alpha = sagemaker$tuner$IntegerParameter(1L, 15L))
```

```{r chunk34}
tuner <- sagemaker$tuner$HyperparameterTuner(estimator             = xgb_estimator,
                                             objective_metric_name = "validation:auc",
                                             objective_type        = "Maximize",
                                             hyperparameter_ranges = hyperp_ranges, 
                                             strategy              = "Bayesian",
                                             max_jobs              = 50L,
                                             max_parallel_jobs     = 2L )

```

```{r chunk35}

algo <- "xgb"
timestamp <- format(Sys.time(), "%Y-%m-%d-%H-%M-%S")
job_name <- paste(project, algo, timestamp, sep = "-")
s3_train_input <- sagemaker$inputs$TrainingInput(s3_data = s3_train,
                                                 content_type = 'csv')
s3_valid_input <- sagemaker$inputs$TrainingInput(s3_data = s3_validation,
                                                 content_type = 'csv')
input_data <- list('train'      = s3_train_input,
                   'validation' = s3_valid_input)
```

```{r chunk36}
tuner$fit(inputs   = input_data, 
          job_name = job_name,
          wait     = FALSE ) # If TRUE, call will wait until job completes
```


```{r chunk37}
session$describe_tuning_job(job_name)[["HyperParameterTuningJobStatus"]]
```


```{r chunk38}
tuning_job_results <- sagemaker$HyperparameterTuningJobAnalytics(job_name)
tuning_results_df <- tuning_job_results$dataframe()
head(tuning_results_df)#[, c(1:4, 6)]

```


```{r chunk39, fig.align='center'}
ggplot(tuning_results_df, aes(TrainingEndTime, FinalObjectiveValue)) +
  geom_point() +
  xlab("Time") +
  ylab(tuning_job_results$description()$TrainingJobDefinition$StaticHyperParameters$`_tuning_objective_metric`) +
  ggtitle("Hyperparameter tuning objective metric",  
          "Progression over the period of all 50 training jobs") +
  theme_minimal()
```


```{r chunk40, fig.align='center'}
ggplot(tuning_results_df, aes(num_round, eta)) +
  geom_point(aes(color = FinalObjectiveValue)) +
  scale_color_viridis("AUC", option = "H") +
  ggtitle("Hyperparameter tuning objective metric progression", 
          "Using a Bayesian strategy") +
  theme_dark()
```


```{r chunk41}
best_tuned_model <- tuning_results_df %>%
                    filter(FinalObjectiveValue == max(FinalObjectiveValue)) %>%
                    filter(alpha == 1) %>%   # there were 2 jobs with max value
                    pull(TrainingJobName)

best_tuned_model

training_job_stats <- session$describe_training_job(job_name = best_tuned_model)

final_metrics <-  map_df(training_job_stats$FinalMetricDataList, 
                          ~tibble(metric_name = .x[["MetricName"]],
                                  value       = .x[["Value"]]))
final_metrics


```


```{r chunk42}
predictions_path <- paste0(models_path, "/", best_tuned_model, "/predictions")

session$create_model_from_job(best_tuned_model)

xgb_batch_predictor <- sagemaker$transformer$Transformer(model_name     = best_tuned_model,
                                                         instance_count = 1L, 
                                                         instance_type  = "ml.m5.4xlarge", 
                                                         strategy       = "MultiRecord",
                                                         assemble_with  = "Line",
                                                         output_path    = predictions_path)

```


```{r chunk43}
xgb_batch_predictor$transform(data         = s3_test, 
                              content_type = 'text/csv',
                              split_type   = "Line",
                              job_name     = best_tuned_model,
                              wait         = FALSE  ) # If TRUE, call will wait until job completes

```

```{r chunk44}
session$describe_transform_job(best_tuned_model)[["TransformJobStatus"]]
```
```{r chunk45}
s3_downloader <- sagemaker$s3$S3Downloader()

s3_test_predictions_path <- s3_downloader$list(predictions_path)
 
dir.create("./predictions")

s3_downloader$download(s3_test_predictions_path, "./predictions")
 
test_predictions <- read_csv("./predictions/churn_test.csv.out",
                              col_names = FALSE) %>% 
                    pull(X1)

churn_test <- read_csv("./data/churn_test_2.csv")

test_results <- tibble(truth       = churn_test$attrition_flag,
                       predictions = test_predictions)

head(test_results)
```

```{r chunk46}
roc_obj <- roc(test_results$truth, 
               test_results$predictions,
               plot        = TRUE,         
               grid        = TRUE,
               print.auc   = TRUE,
               legacy.axes = TRUE, 
               main        = "ROC curve for XGBoost classification using the best model",
               show.thres  = TRUE,
               col         = "red2" )
```

Creating a confusion matrix using the `caret` package we see the following results:

```{r chunk47}
conf_matrix <- confusionMatrix(factor(ifelse(test_results$predictions >= 0.5, 1, 0),
                                      levels = c("0", "1"), 
                                      labels = c("retained", "churned")),
                               factor(test_results$truth, 
                                      levels = c(0, 1), 
                                      labels = c("retained", "churned")),                               
                                positive = "churned")

conf_matrix
```

```{r chunk48}
test_results_pred <- test_results %>% 
                     mutate(pred = factor(ifelse(predictions >= 0.5, 1, 0), 
                                          levels = c("0", "1")))

gmodels::CrossTable(x          = test_results_pred$pred, 
                    y          = test_results_pred$truth,
                    prop.chisq = FALSE, 
                    prop.r     = FALSE, 
                    prop.c     = FALSE, 
                    prop.t     = FALSE,
                    dnn        = c('predicted churn', 'actual churn'))
```
```{r chunk49}
boto_client <- session$boto_session$client("sagemaker")
churn_model <- boto_client$list_models()[["Models"]] %>% 
  map_chr("ModelName") %>% 
  .[[1]]
churn_model
```


```{r chunk50, results='hide'}
config_name <- paste0(churn_model, "-config")
session$create_endpoint_config(name = config_name,
                               model_name =  churn_model, 
                               initial_instance_count = 1L, 
                               instance_type = "ml.m5.large")
```


```{r chunk51, results='hide'}
endpoint_name <- "churn-endpoint"
session$create_endpoint(endpoint_name = endpoint_name, 
                        config_name = config_name,
                        wait = FALSE)
```

```{r chunk52}
boto_client$describe_endpoint(EndpointName = endpoint_name)[["EndpointStatus"]]
```

```{r chunk53}
# Instantiate CSV-Serializer/CSV-Deserializer objects
csv_serializer <- sagemaker$serializers$CSVSerializer()

# csv_serializer$CONTENT_TYPE <- "text/csv" # this is the default
csv_deserializer <- sagemaker$deserializers$CSVDeserializer()

# Instantiate Predictor object
churn_predictor <- sagemaker$predictor$Predictor(endpoint_name     = endpoint_name, 
                                                 sagemaker_session = session, 
                                                 serializer        = csv_serializer,
                                                 deserializer      = csv_deserializer)
```


```{r chunk54, message=FALSE}
test_set <- read_csv("./data/churn_test.csv", 
                     col_names = FALSE, 
                     n_max     = 5) %>% 
            as.matrix()
real_time_predictions <- churn_predictor$predict(data = test_set) %>% 
                         .[[1]] %>% 
                         as.numeric()
```

```{r chunk55, message=FALSE}
batch_predictions <- read_csv("./predictions/churn_test.csv.out", 
                              col_names = FALSE, n_max = 5) %>% 
                     .[[1]]
  
data.frame(real_time_predictions, batch_predictions)
```


```{r chunk56, message=FALSE}
holdout_set <- read_csv("./data/churn_holdout.csv", 
                     col_names = FALSE) %>% 
               as.matrix()
real_time_predictions <- churn_predictor$predict(data = holdout_set) %>% 
                         .[[1]] %>% 
                         as.numeric()
```

```{r chunk57}
churn_holdout_id <- read_csv("data/churn_holdout_id.csv", col_names = FALSE)
submission <- data.frame(churn_holdout_id, real_time_predictions ) %>% 
              rename(id = X1, attrition_flag = real_time_predictions)
write.csv(submission, "sliced_s01_e07_submission.csv", row.names = FALSE)


```


```{r chunk58}
#session$delete_endpoint(endpoint_name)
```
